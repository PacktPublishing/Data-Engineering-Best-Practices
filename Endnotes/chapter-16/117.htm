<html>

<head>
<meta http-equiv=Content-Type content="text/html; charset=windows-1252">
<meta name=Generator content="Microsoft Word 15 (filtered)">
<style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:Courier;
	panose-1:2 7 4 9 2 2 5 2 4 4;}
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
@font-face
	{font-family:Aptos;}
 /* Style Definitions */
 span.P-URL
	{mso-style-name:"P - URL";
	font-family:"Calibri",sans-serif;
	color:blue;
	border:none;
	font-weight:bold;
	font-style:italic;
	text-decoration:underline;}
span.P-Italics
	{mso-style-name:"P - Italics";
	font-family:"Arial",sans-serif;
	border:none;
	font-style:italic;}
p.P-Regular, li.P-Regular, div.P-Regular
	{mso-style-name:"P - Regular";
	margin-top:6.0pt;
	margin-right:0in;
	margin-bottom:6.0pt;
	margin-left:0in;
	line-height:107%;
	font-size:11.0pt;
	font-family:"Aptos",sans-serif;}
span.P-Endnote
	{mso-style-name:"P - Endnote";
	font-family:"Aptos",sans-serif;
	font-variant:normal !important;
	color:windowtext;
	text-transform:none;
	border:none;
	background:white;
	font-style:italic;
	text-decoration:none;
	vertical-align:super;}
p.P-Quote, li.P-Quote, div.P-Quote
	{mso-style-name:"P - Quote";
	margin:0in;
	line-height:115%;
	font-size:10.5pt;
	font-family:"Arial",sans-serif;
	font-style:italic;}
.MsoChpDefault
	{font-size:11.0pt;}
.MsoPapDefault
	{margin-bottom:8.0pt;
	line-height:107%;}
@page WordSection1
	{size:8.5in 11.0in;
	margin:119.5pt 1.5in 131.75pt 1.5in;}
div.WordSection1
	{page:WordSection1;}
 /* List Definitions */
 ol
	{margin-bottom:0in;}
ul
	{margin-bottom:0in;}
-->
</style>

</head>

<body lang=EN-GB link="#467886" vlink="#96607D" style='word-wrap:break-word'>

<div class=WordSection1>

<p class=P-Regular><span class=P-Endnote><span lang=EN style='color:black'>117<br>
</span></span><span lang=EN><a
href="https://www.academia.edu/68372031/AI_Fairness_360_An_Extensible_Toolkit_for_Detecting_Understanding_and_Mitigating_Unwanted_Algorithmic_Bias"><span
class=P-URL>&quot;AI Fairness 360: An extensible toolkit for detecting and
mitigating algorithmic bias&quot;</span></a>; By Rachel KE Bellamy, Kuntal Dey,
Michael Hind, Samuel C Hoffman, Stephanie Houde, Kalapriya Kannan, Pranay
Lohia, Jacquelyn Martino, Sameep Mehta, A Mojsilovic, et al; IBM Journal of
Research and Development 63, 4/5, 4–1; 2019.</span></p>

<p class=P-Regular><span lang=EN>&nbsp;</span></p>

<p class=P-Quote><span lang=EN>&quot;This paper introduces a new open source </span><span
class=P-Italics><span lang=EN style='font-style:normal'>Python</span></span><span
lang=EN> toolkit for algorithmic </span><span class=P-Italics><span lang=EN
style='font-style:normal'>fairness,</span></span><span lang=EN> AI Fairness 360
(AIF360), (<a href="https://github.com/ibm/aif360"><span class=P-URL><span
style='font-style:normal'>https://github.com/ibm/aif360</span></span></a>)
released under an Apache v2.0 license. The main objectives of this toolkit are
to help facilitate the transition of fairness research algorithms to use in an
industrial setting and to provide a common framework for fairness researchers
to share and evaluate algorithms.&quot; - Source: Rachel KE Bellamy</span></p>

<p class=P-Regular><span lang=EN>&nbsp;</span></p>

<p class=P-Regular><span lang=EN>Refer to <a
href="https://www.academia.edu/68372031/AI_Fairness_360_An_Extensible_Toolkit_for_Detecting_Understanding_and_Mitigating_Unwanted_Algorithmic_Bias"><span
class=P-URL>https://www.academia.edu/68372031/AI_Fairness_360_An_Extensible_Toolkit_for_Detecting_Understanding_and_Mitigating_Unwanted_Algorithmic_Bias</span></a>.</span></p>

</div>

</body>

</html>
